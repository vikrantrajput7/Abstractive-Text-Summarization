# Multi-Input Neural Abstractive Text Summarization with Multi-Output

## Introduction

In the modern era of big data, millions of articles, blogs, news reports are generated every
minute. It becomes very difficult to get crucial information from these documents in a very
short time. Automatic text summarization plays an important role in getting information
very quickly from these documents. Text summarization is the task of producing the sum-
mary of the long textual document in such a way that the summary contains the useful and
important information of that textual document.
A news article example is shown in image below.

<img src="https://user-images.githubusercontent.com/26309477/120079996-451c1480-c0d4-11eb-8cae-a432cef5b5e3.jpg" width="500" />
<cite> https://www.techexplorist.com/scientists-developed-electronic-diodes-beyond-5g-performance/32242/ </cite>

### Types of Text Summarization
<p>
<b>1. Extractive Text Summarization</b> <br>
In Extractive Text Summarization, the summary is generated by selecting the important parts
from the source documents such as specific words, phrases, and sentences and then merging
them together to create a coherent summary. <br>
Example : Vikrant went to NLP LAB. There, he setup his system.<br>
Extractive Summary : Vikrant went NLP LAB setup his system.<br>
In the above example, important words are selected and merged to generate the extractive
summary. <br><br>
<b>2. Abstractive Text Summarization</b> <br>
Abstractive Text Summarization compress and paraphrases the source document without los-
ing their semantic meaning and produce a high-quality summary.<br>
Example : Vikrant went to NLP LAB. There, he setup his system.<br>
Abstractive Summary : Vikrant visited NLP LAB to ready the system.<br>
In the above example, sentences are compressed and paraphrased to generate the abstractive
summary.
</p>

# Project Task
<p>
   Input is a text article,
some relevant images, and relevant images’ description and the output is abstractive text
summary and most relevant image to the summary.

</p>
<img src="https://user-images.githubusercontent.com/26309477/120080533-076cbb00-c0d7-11eb-8cb7-bfd90a53b420.jpg" width="300" />

# Dataset Details & Analysis

<p>MSMO dataset has been used.
The size of the data is around 200 GB. <br>The structure of the text article file is shown in Figure below:</p>

<img src="https://user-images.githubusercontent.com/26309477/120080809-21f36400-c0d8-11eb-9753-6e26a7798a59.jpg" width="300" />


<p> Dataset Statistics are given below :<br></p>

|Data                   |  Number of Articles   | No of Images|
| -------------        | -------------         |  ----------
|Training Data          |   293625              | 1876934|
|Validation Data        |   10339               | 71463|
|Test Data              |   10245               | 68414|

<br>
<b> Train, Validation, Test Documents Words count Distribution : </b>

<img src="https://user-images.githubusercontent.com/26309477/120082409-874b5300-c0e0-11eb-9db3-135a011d6d8d.png" width="600" />


# System Architecture

In system architecture, the text articles
and images with descriptions have taken as an input and then abstractive summary with best 
related image has generated as an output. To do this task, the first text article is given as
input to the encoder-decoder model and a summary is generated. Then the BLEU score is
calculated between the generated summary and the image descriptions. The image with the
highest BLEU score between summary and description is output as the most relevant image
to the article. The whole process is shown in Figure below:


<img src="https://user-images.githubusercontent.com/26309477/120082624-8e269580-c0e1-11eb-81e7-5e79b253ada4.jpg" width="600" />

<b>Encoder - Decoder with Attention Model Architecture :</b>

<img src="https://user-images.githubusercontent.com/26309477/120082654-bf06ca80-c0e1-11eb-8317-bbfbeb6484f5.jpg" width="300" />


# Experiment

### Data Pre-Processing
<p>
Text articles have been pre-processed
where all the text converted into the lower case, punctuation marks and special symbols like
#, $, % have been removed. Source articles have been truncated after 110 words. The target
summary has been truncated after 26 words. A text article example before pre-processing
and after pre-processing is shown in Figures below:
</p>

<img src="https://user-images.githubusercontent.com/26309477/120082771-6683fd00-c0e2-11eb-8101-afb06c261d4f.jpg" width="500" />

<img src="https://user-images.githubusercontent.com/26309477/120082776-6ab01a80-c0e2-11eb-81a2-d186c3366984.jpg" width="500" />

### Creating Vocabulary
<p>
There are a total of 234682 unique words in source training articles. Only the top 230000 most
frequent words are taken in the source vocabulary. Including start and end token, the total source vocab size is 230002.

There are a total of 88631 unique words in the target training summary. Only the top 85000
most frequent words are taken for the target vocabulary. Including start and end token, the
total target vocab size is 85004.
</p>
 
 <img src="https://user-images.githubusercontent.com/26309477/120082861-f45fe800-c0e2-11eb-8f9c-17130b59ec86.png" width="600" />

### Model Training

<p>
   The model was trained for 90000 epochs with a batch size of 128. The best validation ac-
curacy was on 89000 epoch. So summary was generated on the 89000 epoch model. Model
weights were saved for every 1000 epochs. It took around 7 hours 44 minutes to train the
model.
 </p>

 <img src="https://user-images.githubusercontent.com/26309477/120082955-74864d80-c0e3-11eb-841d-bd4d8b5f4fb4.png" width="600" />

# Results & Analysis
<p>
We have evaluated our generated summary on BLEU score and ROUGE score.
 </p>
 
<b> BLEU Score Results :</b>
 

|Performance Measure                   |  Score with <unk> token   | Score without <unk> token|
| -------------                        | -------------             |  ----------
|BLEU-1         |   39.3              | 39.3|
|BLEU-2        |   18.5              | 18.6|
|BLEU-3              |   10.1              | 10.1|
|BLEU-4             |   6.2              | 6.2|
 |BLEU            |   11.87             | 11.87|
 
<b> ROUGE Score Results :</b>
 
 
 |Performance Measure                   |  Score with <unk> token   | Score without <unk> token|
| -------------                        | -------------             |  ----------
|ROUGE-1        |   37.06              | 35.75|
|ROUGE-2       |   17.06              | 15.61|
|ROUGE-3            |   30.02              | 28.64|
 
## Output Summary Examples
   
   ### Best Summary Results
   
   <img src="https://user-images.githubusercontent.com/26309477/120083309-72bd8980-c0e5-11eb-8152-dde180648779.jpg" width="400" />
 
   ### Average Summary Results
   
   <img src="https://user-images.githubusercontent.com/26309477/120083310-77823d80-c0e5-11eb-8f4f-71a53316a3ad.jpg" width="400" />

   
### Worst Summary Results
   
<img src="https://user-images.githubusercontent.com/26309477/120083315-7e10b500-c0e5-11eb-9ffa-6879652109d9.jpg" width="400" />
   
   
# References
  <p>
[1] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning with neural
networks,” in Advances in Neural Information Processing Systems 27, Z. Ghahramani,
M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates,
Inc., 2014, pp. 3104–3112. [Online]. Available: http://papers.nips.cc/paper/5346-
sequence-to-sequence-learning-with-neural-networks.pdf <br>
[2] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
learning to align and translate,”
in 3rd International Conference on Learn-
ing Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference
Track Proceedings, Y. Bengio and Y. LeCun, Eds., 2015. [Online]. Available:
http://arxiv.org/abs/1409.0473 <br>
[3] M. Luong, H. Pham, and C. D. Manning, “Effective approaches to attention-based
neural machine translation,” CoRR, vol. abs/1508.04025, 2015. [Online]. Available:
http://arxiv.org/abs/1508.04025 <br>
[4] A. M. Rush, S. Chopra, and J. Weston, “A neural attention model for ab-
stractive sentence summarization,” in Proceedings of the 2015 Conference on Em-
pirical Methods in Natural Language Processing.
Lisbon, Portugal: Association
for Computational Linguistics, Sep. 2015, pp. 379–389. [Online]. Available:
https://www.aclweb.org/anthology/D15-1044 <br>
[5] K. Lopyrev, “Generating news headlines with recurrent neural networks,” CoRR, vol.
abs/1512.01712, 2015. [Online]. Available: http://arxiv.org/abs/1512.01712 <br>
[6] R. Nallapati, B. Zhou, C. dos Santos, Ç. GuÌ‡lçehre, and B. Xiang, “Abstractive
text summarization using sequence-to-sequence RNNs and beyond,” in Proceedings of
The 20th SIGNLL Conference on Computational Natural Language Learning. Berlin,
Germany: Association for Computational Linguistics, Aug. 2016, pp. 280–290.
[Online]. Available: https://www.aclweb.org/anthology/K16-1028 <br>
[7] A. See, P. J. Liu, and C. D. Manning, “Get to the point:
Summarization
with pointer-generator networks,” in Proceedings of the 55th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers). Vancouver,
Canada: Association for Computational Linguistics, Jul. 2017, pp. 1073–1083.
[Online]. Available: https://www.aclweb.org/anthology/P17-1099  <br>
[8] H. Li, J. Zhu, C. Ma, J. Zhang, and C. Zong, “Multi-modal summarization for
asynchronous collection of text, image, audio and video,” in Proceedings of the 2017
Conference on Empirical Methods in Natural Language Processing.
Copenhagen,  
Denmark: Association for Computational Linguistics, Sep. 2017, pp. 1092–1102.
[Online]. Available: https://www.aclweb.org/anthology/D17-1114   <br>
[9] J. Zhu, H. Li, T. Liu, Y. Zhou, J. Zhang, and C. Zong, “MSMO: Multimodal
summarization with multimodal output,” in Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Processing. Brussels, Belgium: Association
for Computational Linguistics, Oct.-Nov. 2018, pp. 4154–4164. [Online]. Available:
https://www.aclweb.org/anthology/D18-1448 <br>
[10] Y. Jaya Kumar, O. S. Goh, H. Basiron, H. C. Ngo, and P. Suppiah, “A review on auto-
matic text summarization approaches,” vol. 12, pp. 178–190, 01 2016. <br>
[11] T. Shi, Y. Keneshloo, N. Ramakrishnan, and C. K. Reddy, “Neural abstractive text
summarization with sequence-to-sequence models,” CoRR, vol. abs/1812.02303, 2018.
[Online]. Available: http://arxiv.org/abs/1812.02303  <br>
[12] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a method for automatic
evaluation of machine translation,” in Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics.
Philadelphia, Pennsylvania, USA:
Association for Computational Linguistics, Jul. 2002, pp. 311–318. [Online].
Available: https://www.aclweb.org/anthology/P02-1040  <br>
[13] C.-Y.
Lin,
“ROUGE: A package
for automatic evaluation of summaries,” in Text Summarization Branches Out. 
Barcelona, Spain:
Association for Computational Linguistics, Jul. 2004, pp. 74–81. [Online]. Available:
https://www.aclweb.org/anthology/W04-1013  <br>
[14] A. Nenkova and R. Passonneau, “Evaluating content selection in summarization:
The pyramid method,” in Proceedings of the Human Language Technology Confer-
ence of the North American Chapter of the Association for Computational Linguistics:
HLT-NAACL 2004.
Boston, Massachusetts, USA: Association for Computa-
tional Linguistics, May 2 - May 7 2004, pp. 145–152. [Online]. Available:
https://www.aclweb.org/anthology/N04-1019   <br>
[15] S. Song, H. Huang, and T. Ruan, “Abstractive text summarization using lstm-cnn
based deep learning,” Multimedia Tools and Applications, vol. 78, no. 1, pp. 857–875,
2019. [Online]. Available: https://doi.org/10.1007/s11042-018-5749-3 <br>
[16] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation,
vol. 9, no. 8, pp. 1735–1780, 1997. <br>
[17] K. Cho, B. van Merriënboer, D. Bahdanau, and Y. Bengio, “On the properties of
neural machine translation: Encoder–decoder approaches,” in Proceedings of SSST-8,
Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. Doha,
Qatar: Association for Computational Linguistics, Oct. 2014, pp. 103–111. [Online].
Available: https://www.aclweb.org/anthology/W14-4012  <br>
[18] H. Li, J. Zhu, T. Liu, J. Zhang, and C. Zong, “Multi-modal sentence summarization
with modality attention and image filtering,” in Proceedings of the Twenty-Seventh
International Joint Conference on Artificial Intelligence, IJCAI-18. International Joint
Conferences on Artificial Intelligence Organization, 7 2018, pp. 4152–4158. [Online].
Available: https://doi.org/10.24963/ijcai.2018/577 <br>
[19] G. Klein, Y. Kim, Y. Deng, V. Nguyen, J. Senellart, and A. Rush, “OpenNMT: Neural
machine translation toolkit,” in Proceedings of the 13th Conference of the Association
for Machine Translation in the Americas (Volume 1: Research Papers). Boston, MA:
Association for Machine Translation in the Americas, Mar. 2018, pp. 177–184.
[Online]. Available: https://www.aclweb.org/anthology/W18-1817 <br>
[20] J. Chung, Ç. Gülçehre, K. Cho, and Y. Bengio, “Empirical evaluation of gated
recurrent neural networks on sequence modeling,” CoRR, vol. abs/1412.3555, 2014.
[Online]. Available: http://arxiv.org/abs/1412.3555  <br>
 </p>
 
# Thesis Recommendation Sheet
   
   <img src="https://user-images.githubusercontent.com/26309477/120083696-2cb5f500-c0e8-11eb-9a48-b33c71b94ad9.jpg" width="400" />
   
# Publications

<p>

<b>Text summary evaluation based on interpretable semantic textual similarity </b> <br> 
Majumder, G., Rajput, V., Pakray, P. et al. . Multimed Tools Appl (2022). <br> 
https://doi.org/10.1007/s11042-022-14082-6

</p>
